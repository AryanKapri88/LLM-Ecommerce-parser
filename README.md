The developed API successfully extracted meaningful attributes from the HTML blocks and returned the information in JSON format. However, due to the constraints of using a low-end PC, the API throws an error when processing large HTML files like index.html due to the exceeding number of tokens. This issue can be addressed by preprocessing the HTML file using NLP libraries to tokenize and feed the model in chunks.

**Sample Output**

The sample folder contains a small part of the index.html and its corresponding output. Due to the limitations of my low-end PC, it was not possible to process the entire index.html file within the expected time. The sample folder demonstrates the extraction process and the format of the output.

                                                              `sample.ipynb`: 

<img width="610" alt="11" src="https://github.com/AryanKapri88/LLM-ecommerce-parser/assets/110614822/e717a03b-7ec8-4584-aefb-07a9a7c1ae84">

                                                              `api_main.py`:

<img width="593" alt="Capture" src="https://github.com/AryanKapri88/LLM-ecommerce-parser/assets/110614822/f5c348f4-f57a-48b4-9a08-a21d66d5d28b">


This project showcases my ability to apply advanced machine learning techniques to solve practical problems, despite hardware constraints and time limitations. The provided code and methodology offer a foundation for further enhancement and scalability.
